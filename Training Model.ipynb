{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f084ca82-f172-4128-ad6d-e43f7560c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, AvgPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc42475b-41b6-4d3a-8eca-3349b82be9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9579fe90-d612-4551-a52e-100709bd0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9103132f-6f24-4503-9b86-1b8a4ea2875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 189 images belonging to 3 classes.\n",
      "Found 62 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split=0.25,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        #width_shift_range = 0.2,\n",
    "        #height_shift_range = 0.2\n",
    "                                  )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(validation_split=0.25,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        #width_shift_range = 0.2,\n",
    "        #height_shift_range = 0.2\n",
    "                                       )\n",
    "\n",
    "train_datagen_flow = train_datagen.flow_from_directory(\n",
    "    'Faces/',\n",
    "    target_size=(480, 640),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=12345)\n",
    "\n",
    "val_datagen_flow = validation_datagen.flow_from_directory(\n",
    "    'Faces/',\n",
    "    target_size=(480, 640),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=12345) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c859ffb1-3acf-4ad6-851c-665790ce5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = next(train_datagen_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc2bb75-0d5f-4ffa-9ef4-99588814948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 1., 2., 2., 2., 2., 1., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fce3471-f9f5-4761-aa55-f3ca349d35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aebb00-7896-4565-a978-89146a9fe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.add_subplot(4,4, 1)\n",
    "print(target[0])\n",
    "plt.imshow(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1374e617-2bc2-441d-ab4e-d1fdd2666709",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet50(input_shape=(480, 640, 3),\n",
    "                   weights='imagenet', \n",
    "                   include_top=False)\n",
    "model = Sequential()\n",
    "model.add(backbone)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f3d5bbe-a43a-4818-8196-249dc71dd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_datagen_flow)\n",
    "validation_steps = len(val_datagen_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ade989-6b7b-41b6-8cf4-9ff846476562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 15, 20, 2048)      23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7494d63-3dea-4c97-b83c-18afeea26d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_datagen_flow, \n",
    "              validation_data=val_datagen_flow,\n",
    "              epochs=20,\n",
    "              batch_size=1,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f7ca134c-d425-4950-97ff-f74af302fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b4cd99e7-3741-41e7-a0bf-252b426c0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "return_value, image = camera.read()\n",
    "cv2.imwrite('opencv.png', image)\n",
    "del(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bcbbba42-c4b0-4253-aa71-1c85c239fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "image = tf.keras.preprocessing.image.load_img('opencv.png', target_size=(480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c85fb9b6-3b03-4984-bed7-688028f6da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "49c729d2-0ed6-4b8d-92fa-c261c307934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = input_arr.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20048a9-273d-4141-aa5d-ba2d2844f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.add_subplot(4,4, 1)\n",
    "plt.imshow(input_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a9eec917-537a-44f2-bde8-547023bee573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 614ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(input_arr)\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1ff1f3ef-f03d-4e00-aed1-49dbb69bda6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11142045, 0.07434054, 0.814239  ]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c90d2187-bdb3-4f28-bad4-8d2d801c0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_keras.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "905d43561ac1665169cf5ed8e3132a294a102fd702471e0bbd121ed83ef27511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
